{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geotrellis.proj4.CRS\n",
    "import geotrellis.raster.{ArrayTile, DoubleArrayTile, Tile}\n",
    "import geotrellis.raster.io.geotiff.writer.GeoTiffWriter\n",
    "import geotrellis.raster.io.geotiff.{SinglebandGeoTiff, _}\n",
    "import geotrellis.spark.io.hadoop._\n",
    "import geotrellis.vector.{Extent, ProjectedExtent}\n",
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.{SparkConf, SparkContext}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "band_count = 1\n",
       "projected_extent = ProjectedExtent(Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7)\n",
       "num_cols_rows = (7808,3892)\n",
       "band_RDD = MapPartitionsRDD[40] at map at <console>:86\n",
       "band_vec = EmptyRDD[9] at emptyRDD at <console>:44\n",
       "band0 = MapPartitionsRDD[39] at map at <console>:83\n",
       "band0_index = MapPartitionsRDD[34] at map at <console>:79\n",
       "pattern = 2.tif\n",
       "filepath = hdfs:///user/hadoop/spring-index/LastFreeze/1980.tif\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hdfs:///user/hadoop/spring-index/LastFreeze/1980.tif"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val band_count = 1;\n",
    "    var projected_extent = new ProjectedExtent(new Extent(0,0,0,0), CRS.fromName(\"EPSG:3857\"))\n",
    "    var num_cols_rows :(Int, Int) = (0, 0)\n",
    "    var band_RDD: RDD[Array[Double]] = sc.emptyRDD\n",
    "    var band_vec: RDD[Vector] = sc.emptyRDD\n",
    "    var band0: RDD[(Long, Double)] = sc.emptyRDD\n",
    "    var band0_index: RDD[Long] = sc.emptyRDD\n",
    "    val pattern: String = \"2.tif\"\n",
    "    var filepath: String = \"\"\n",
    "    if (band_count == 1) {\n",
    "      //Single band GeoTiff\n",
    "      filepath = \"hdfs:///user/hadoop/spring-index/LastFreeze/1980.tif\"\n",
    "    } else {\n",
    "      //Multi band GeoTiff\n",
    "      filepath = \"hdfs:///user/hadoop/spring-index/BloomFinal/1980.tif\"\n",
    "    }\n",
    "\n",
    "    if (band_count == 1) {\n",
    "      //Lets load a Singleband GeoTiff and return RDD just with the tiles.\n",
    "      //Since it is a single GeoTiff, it will be a RDD with a tile.\n",
    "      val tiles_RDD = sc.hadoopGeoTiffRDD(filepath).values\n",
    "      val bands_RDD = tiles_RDD.map(m => m.toArrayDouble())\n",
    "\n",
    "      val extents_withIndex = sc.hadoopGeoTiffRDD(filepath).keys.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "      projected_extent = (extents_withIndex.filter(m => m._1 == 0).values.collect())(0)\n",
    "\n",
    "      val tiles_withIndex = tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "      //num_cols_rows = (tiles_withIndex.lookup(0).apply(0).cols, tiles_withIndex.lookup(0).apply(0).rows)\n",
    "      val tile0 = (tiles_withIndex.filter(m => m._1==0).values.collect())(0)\n",
    "      num_cols_rows = (tile0.cols,tile0.rows)\n",
    "        \n",
    "      println(tile0.cellType)\n",
    "\n",
    "      //Get Index for Cells\n",
    "      val bands_withIndex = bands_RDD.zipWithIndex().map { case (e, v) => (v, e) }\n",
    "      //band0_index = bands_withIndex.lookup(0).apply(0).zipWithIndex.filter{ case (v, i) => !v.isNaN }.map { case (v, i) => (i) }\n",
    "      //val band0_index = bands_withIndex.lookup(0).apply(0).zipWithIndex.filter(m => !m._1.isNaN).take(sample).map { case (v, i) => (i) }\n",
    "      band0_index = bands_withIndex.filter(m => m._1 == 0).values.flatMap(m => m).zipWithIndex.filter(m => !m._1.isNaN).map { case (v, i) => (i) }\n",
    "\n",
    "      //Get Array[Double] of a Title to later store the cluster ids.\n",
    "      //band0 = sc.parallelize(bands_withIndex.lookup(0).take(1)).flatMap( m => m).zipWithIndex.map{case (v,i) => (i,v)}\n",
    "      band0 = bands_withIndex.filter(m => m._1 == 0).values.flatMap( m => m).zipWithIndex.map{case (v,i) => (i,v)}\n",
    "\n",
    "      //Lets filter out NaN\n",
    "      band_RDD = bands_RDD.map(m => m.filter(!_.isNaN))\n",
    "    } else {\n",
    "      //Lets load a Multiband GeoTiff and return RDD just with the tiles.\n",
    "      //Since it is a multi-band GeoTiff, we will take band 4\n",
    "      val tiles_RDD = sc.hadoopMultibandGeoTiffRDD(filepath).values\n",
    "      val bands_RDD = tiles_RDD.map(m => m.band(3).toArrayDouble())\n",
    "\n",
    "      val extents_withIndex = sc.hadoopGeoTiffRDD(filepath).keys.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "      projected_extent = (extents_withIndex.filter(m => m._1 == 0).values.collect())(0)\n",
    "\n",
    "      val tiles_withIndex = tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "      val tile0 = (tiles_withIndex.filter(m => m._1==0).values.collect())(0)\n",
    "      num_cols_rows = (tile0.cols,tile0.rows)\n",
    "\n",
    "      //Get Index for Cells\n",
    "      val bands_withIndex = bands_RDD.zipWithIndex().map { case (e, v) => (v, e) }\n",
    "      //band0_index = bands_withIndex.lookup(0).apply(0).zipWithIndex.filter { case (v, i) => !v.isNaN }.take(sample).map { case (v, i) => (i) }\n",
    "      band0_index = bands_withIndex.filter(m => m._1 == 0).values.flatMap(m => m).zipWithIndex.filter(m => !m._1.isNaN).map { case (v, i) => (i) }\n",
    "\n",
    "      //Get Array[Double] of a Title to later store the cluster ids.\n",
    "      band0 = bands_withIndex.filter(m => m._1 == 0).values.flatMap( m => m).zipWithIndex.map{case (v,i) => (i,v)}\n",
    "\n",
    "      //Let's filter out NaN\n",
    "      band_RDD = bands_RDD.map(m => m.filter(v => !v.isNaN))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: lastException: Throwable = null\n",
       "<console>:42: error: not found: value band0\n",
       "           val cluster_tile = DoubleArrayTile(band0.values.collect(), num_cols_rows._1, num_cols_rows._2)\n",
       "                                              ^\n",
       "<console>:42: error: not found: value num_cols_rows\n",
       "           val cluster_tile = DoubleArrayTile(band0.values.collect(), num_cols_rows._1, num_cols_rows._2)\n",
       "                                                                      ^\n",
       "<console>:42: error: not found: value num_cols_rows\n",
       "           val cluster_tile = DoubleArrayTile(band0.values.collect(), num_cols_rows._1, num_cols_rows._2)\n",
       "                                                                                        ^\n",
       "<console>:43: error: not found: value projected_extent\n",
       "           val geoTiff = SinglebandGeoTiff(cluster_tile, projected_extent.extent, projected_extent.crs, Tags.empty, GeoTiffOptions.DEFAULT)\n",
       "                                                         ^\n",
       "<console>:43: error: not found: value projected_extent\n",
       "           val geoTiff = SinglebandGeoTiff(cluster_tile, projected_extent.extent, projected_extent.crs, Tags.empty, GeoTiffOptions.DEFAULT)\n",
       "                                                                                  ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    /*\n",
    "     Create a GeoTiff and save to HDFS.\n",
    "    */\n",
    "\n",
    "    val cluster_tile = DoubleArrayTile(band0.values.collect(), num_cols_rows._1, num_cols_rows._2)\n",
    "    val geoTiff = SinglebandGeoTiff(cluster_tile, projected_extent.extent, projected_extent.crs, Tags.empty, GeoTiffOptions.DEFAULT)\n",
    "\n",
    "    //sc.parallelize(GeoTiffWriter.write(geoTiff)).saveAsObjectFile(\"hdfs:///users/emma/spring-index/BloomFinal/clusters_3.tif\")\n",
    "    GeoTiffWriter.write(geoTiff, \"/tmp/test3.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
