{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask a GeoTiff\n",
    "\n",
    "In this notebook the user can load two GeoTiffs, extract a Tile from the first GeoTiff and mask it with second GeoTiff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import geotrellis.proj4.CRS\n",
    "import geotrellis.raster.io.geotiff.writer.GeoTiffWriter\n",
    "import geotrellis.raster.io.geotiff.{SinglebandGeoTiff, _}\n",
    "import geotrellis.raster.{DoubleArrayTile, Tile}\n",
    "import geotrellis.spark.io.hadoop._\n",
    "import geotrellis.vector.io.json.GeoJson\n",
    "import geotrellis.vector.io.wkb.WKB\n",
    "import geotrellis.vector._\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "\n",
    "//Spire is a numeric library for Scala which is intended to be generic, fast, and precise.\n",
    "import spire.syntax.cfor._\n",
    "\n",
    "//spray-json to parse strings as json\n",
    "import spray.json._\n",
    "import spray.json.JsonFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_projected_extent = ProjectedExtent(Extent(-171.1296209227216, 19.996701428244357, -42.56469205974807, 49.99999999547987),geotrellis.proj4.CRS$$anon$3@41d0d1b7)\n",
       "geo_num_cols_rows = (17800,4154)\n",
       "geo_path = hdfs:///user/hadoop/modis/Onset_Greenness_Maximum/A2001001__Onset_Greenness_Maximum.tif\n",
       "geo_tiles_RDD = MapPartitionsRDD[16] at values at <console>:101\n",
       "geo_extents_withIndex = MapPartitionsRDD[21] at map at <console>:103\n",
       "geo_projected_extent = ProjectedExtent(Extent(-171.1296209227216, 19.996701428244357, -42.56469205974807, 49.99999999547987),geotrellis.proj4.CRS$$anon$3@41d0d...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ProjectedExtent(Extent(-171.1296209227216, 19.996701428244357, -42.56469205974807, 49.99999999547987),geotrellis.proj4.CRS$$anon$3@41d0d1b7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var geo_projected_extent = new ProjectedExtent(new Extent(0,0,0,0), CRS.fromName(\"EPSG:3857\"))\n",
    "var geo_num_cols_rows :(Int, Int) = (0, 0)\n",
    "val geo_path = \"hdfs:///user/hadoop/modis/Onset_Greenness_Maximum/A2001001__Onset_Greenness_Maximum.tif\"\n",
    "val geo_tiles_RDD = sc.hadoopGeoTiffRDD(geo_path).values\n",
    "\n",
    "val geo_extents_withIndex = sc.hadoopMultibandGeoTiffRDD(geo_path).keys.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "geo_projected_extent = (geo_extents_withIndex.filter(m => m._1 == 0).values.collect())(0)\n",
    "\n",
    "val geo_tiles_withIndex = geo_tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "val geo_tile0 = (geo_tiles_withIndex.filter(m => m._1==0).values.collect())(0)\n",
    "geo_num_cols_rows = (geo_tile0.cols, geo_tile0.rows)\n",
    "val geo_cellT = geo_tile0.cellType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Mask as GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:268: error: Cannot find JsonReader or JsonFormat type class for geotrellis.vector.Polygon\n",
       "val geom :Geometry = geojson.convertTo[Polygon]\n",
       "                                      ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val geojson_path = \"/user/hadoop/modis/usa_mask.geojson\"\n",
    "val geojson_file = sc.wholeTextFiles(geojson_path)\n",
    "//val geojson :String = geojson_file.first()._2.parseJson.prettyPrint\n",
    "val geojson = \"\"\"{\n",
    "        |  \"type\": \"Polygon\",\n",
    "        |  \"coordinates\": [[[0.0, 0.0], [0.0, 1.0], [1.0, 1.0], [0.0, 0.0]]]\n",
    "        |}\"\"\".stripMargin.parseJson\n",
    "val geom :Geometry = geojson.convertTo[Polygon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:52: error: not found: value geom\n",
       "       val res_tile = geo_tile0.mask(geo_projected_extent.extent,geom)\n",
       "                                                                 ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val res_tile = geo_tile0.mask(geo_projected_extent.extent,geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:47: error: not found: value res_tile\n",
       "       val clone_tile = DoubleArrayTile(res_tile, geo_num_cols_rows._1, geo_num_cols_rows._2)\n",
       "                                        ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val clone_tile = DoubleArrayTile(res_tile, geo_num_cols_rows._1, geo_num_cols_rows._2)\n",
    "\n",
    "val cloned = geotrellis.raster.DoubleArrayTile.empty(geo_num_cols_rows._1, geo_num_cols_rows._2)\n",
    "cfor(0)(_ < geo_num_cols_rows._1, _ + 1) { col =>\n",
    "    cfor(0)(_ < geo_num_cols_rows._2, _ + 1) { row =>\n",
    "        val v = clone_tile.getDouble(col, row)\n",
    "        cloned.setDouble(col, row, v)\n",
    "    }\n",
    "}\n",
    "\n",
    "val geoTif = new SinglebandGeoTiff(cloned, geo_projected_extent.extent, geo_projected_extent.crs, Tags.empty, GeoTiffOptions(compression.DeflateCompression))\n",
    "\n",
    "//Save GeoTiff to /tmp\n",
    "val output = \"/user/pheno/modis/Onset_Greenness_Maximum/A2001001__Onset_Greenness_Maximum_masked.tif\"\n",
    "val tmp_output = \"/tmp/A2001001__Onset_Greenness_Maximum_masked.tif\"\n",
    "GeoTiffWriter.write(geoTif, tmp_output)\n",
    "\n",
    "//Upload to HDFS\n",
    "var cmd = \"hadoop dfs -copyFromLocal -f \" + tmp_output + \" \" + output\n",
    "Process(cmd)!\n",
    "\n",
    "cmd = \"rm -fr \" + tmp_output\n",
    "Process(cmd)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
