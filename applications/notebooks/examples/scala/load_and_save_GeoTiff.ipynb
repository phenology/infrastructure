{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and save a GeoTiff\n",
    "\n",
    "In this notebook the user can load a GeoTiff, extract a Tile and its metadata information to create a new GeoTiff, i.e., a clone. The clone is then upload to HDFS using a System command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import geotrellis.proj4.CRS\n",
    "import geotrellis.raster.io.geotiff.writer.GeoTiffWriter\n",
    "import geotrellis.raster.io.geotiff.{SinglebandGeoTiff, _}\n",
    "import geotrellis.raster.{CellType, DoubleArrayTile}\n",
    "import geotrellis.spark.io.hadoop._\n",
    "import geotrellis.vector.{Extent, ProjectedExtent}\n",
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "\n",
    "//Spire is a numeric library for Scala which is intended to be generic, fast, and precise.\n",
    "import spire.syntax.cfor._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projected_extent = ProjectedExtent(Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7)\n",
       "num_cols_rows = (7808,3892)\n",
       "grid0 = MapPartitionsRDD[113] at map at <console>:123\n",
       "filepath = hdfs:///user/hadoop/spring-index/LastFreeze/1980.tif\n",
       "tiles_RDD = MapPartitionsRDD[94] at values at <console>:110\n",
       "grids_RDD = MapPartitionsRDD[95] at map at <console>:111\n",
       "extents_withIndex = MapPartitionsRDD[100] at map at <console>:113\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "projected_extent: geotrellis.vector.ProjectedExten...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[100] at map at <console>:113"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var projected_extent = new ProjectedExtent(new Extent(0,0,0,0), CRS.fromName(\"EPSG:3857\"))\n",
    "var num_cols_rows :(Int, Int) = (0, 0)\n",
    "//var cellT :CellType = CellType.fromName(\"uint8raw\")\n",
    "var grid0: RDD[(Long, Double)] = sc.emptyRDD\n",
    "  \n",
    "//Single band GeoTiff\n",
    "val filepath = \"hdfs:///user/hadoop/spring-index/LastFreeze/1980.tif\"\n",
    "\n",
    "//Since it is a single GeoTiff, it will be a RDD with a tile.\n",
    "val tiles_RDD = sc.hadoopGeoTiffRDD(filepath).values\n",
    "val grids_RDD = tiles_RDD.map(m => m.toArrayDouble())\n",
    "\n",
    "val extents_withIndex = sc.hadoopGeoTiffRDD(filepath).keys.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "projected_extent = (extents_withIndex.filter(m => m._1 == 0).values.collect())(0)\n",
    "\n",
    "val tiles_withIndex = tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "val tile0 = (tiles_withIndex.filter(m => m._1==0).values.collect())(0)\n",
    "num_cols_rows = (tile0.cols,tile0.rows)\n",
    "        \n",
    "val cellT = tile0.cellType\n",
    "\n",
    "val bands_withIndex = grids_RDD.zipWithIndex().map { case (e, v) => (v, e) }\n",
    "grid0 = bands_withIndex.filter(m => m._1 == 0).values.flatMap( m => m).zipWithIndex.map{case (v,i) => (i,v)}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clone_tile = DoubleConstantNoDataArrayTile([D@718e69bf,7808,3892)\n",
       "cloned = UByteRawArrayTile([B@62ba2e40,7808,3892)\n",
       "geoTif = SinglebandGeoTiff(UByteRawArrayTile([B@62ba2e40,7808,3892),Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7,Tags(Map(),List()),GeoTiffOptions(geotrellis.raster.io.geotiff.Striped@e91c2e7,geotrellis.raster.io.geotiff.compression.NoCompression$@6f3deffe,1,None))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SinglebandGeoTiff(UByteRawArrayTile([B@62ba2e40,7808,3892),Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7,Tags(Map(),List()),GeoTiffOptions(geotrellis.raster.io.geotiff.Striped@e91c2e7,geotrellis.raster.io.geotiff.compression.NoCompression$@6f3deffe,1,None))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val clone_tile = DoubleArrayTile(grid0.values.collect(), num_cols_rows._1, num_cols_rows._2)\n",
    "\n",
    "val cloned = geotrellis.raster.ArrayTile.empty(cellT, num_cols_rows._1, num_cols_rows._2)\n",
    "cfor(0)(_ < num_cols_rows._1, _ + 1) { col =>\n",
    "    cfor(0)(_ < num_cols_rows._2, _ + 1) { row =>\n",
    "        val v = clone_tile.getDouble(col, row)\n",
    "        cloned.setDouble(col, row, v)\n",
    "    }\n",
    "}\n",
    "\n",
    "val geoTif = new SinglebandGeoTiff(cloned, projected_extent.extent, projected_extent.crs, Tags.empty, GeoTiffOptions.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a GeoTiff to **/tmp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output = /user/emma/spring-index/LastFreeze/1980_clone.tif\n",
       "tmp_output = /tmp/1980_clone.tif\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/tmp/1980_clone.tif"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val output = \"/user/emma/spring-index/LastFreeze/1980_clone.tif\"\n",
    "val tmp_output = \"/tmp/1980_clone.tif\"\n",
    "GeoTiffWriter.write(geoTif, tmp_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a GeoTiff to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: Use of this script to execute hdfs command is deprecated.\n",
      "Instead use the hdfs command for it.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cmd = hadoop dfs -copyFromLocal -f /tmp/1980_clone.tif /user/emma/spring-index/LastFreeze/1980_clone.tif\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cmd = \"hadoop dfs -copyFromLocal -f \" + tmp_output + \" \" + output\n",
    "Process(cmd)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
