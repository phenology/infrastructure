{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask a GeoTiff\n",
    "\n",
    "In this notebook the user can load two GeoTiffs, extract a Tile from the first GeoTiff and mask it with second GeoTiff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import geotrellis.proj4.CRS\n",
    "import geotrellis.raster.io.geotiff.writer.GeoTiffWriter\n",
    "import geotrellis.raster.io.geotiff.{SinglebandGeoTiff, _}\n",
    "import geotrellis.raster.{CellType, DoubleArrayTile}\n",
    "import geotrellis.spark.io.hadoop._\n",
    "import geotrellis.vector.{Extent, ProjectedExtent}\n",
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "\n",
    "//Spire is a numeric library for Scala which is intended to be generic, fast, and precise.\n",
    "import spire.syntax.cfor._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "geo_projected_extent = ProjectedExtent(Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7)\n",
       "geo_num_cols_rows = (7808,3892)\n",
       "geo_path = hdfs:///user/hadoop/spring-index/BloomFinal/1980.tif\n",
       "geo_tiles_RDD = MapPartitionsRDD[2] at values at <console>:49\n",
       "geo_extents_withIndex = MapPartitionsRDD[7] at map at <console>:51\n",
       "geo_projected_extent = ProjectedExtent(Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "geo_tiles_withIndex: org.apache.s...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ProjectedExtent(Extent(-126.30312894720473, 14.29219617034159, -56.162671563152486, 49.25462702827337),geotrellis.proj4.CRS$$anon$3@41d0d1b7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var geo_projected_extent = new ProjectedExtent(new Extent(0,0,0,0), CRS.fromName(\"EPSG:3857\"))\n",
    "var geo_num_cols_rows :(Int, Int) = (0, 0)\n",
    "val geo_path = \"hdfs:///user/hadoop/spring-index/BloomFinal/1980.tif\"\n",
    "val geo_tiles_RDD = sc.hadoopGeoTiffRDD(geo_path).values\n",
    "\n",
    "val geo_extents_withIndex = sc.hadoopMultibandGeoTiffRDD(geo_path).keys.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "geo_projected_extent = (geo_extents_withIndex.filter(m => m._1 == 0).values.collect())(0)\n",
    "\n",
    "val geo_tiles_withIndex = geo_tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "val geo_tile0 = (geo_tiles_withIndex.filter(m => m._1==0).values.collect())(0)\n",
    "geo_num_cols_rows = (geo_tile0.cols, geo_tile0.rows)\n",
    "val geo_cellT = geo_tile0.cellType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask_path = hdfs:///user/hadoop/usa_mask.tif\n",
       "mask_tiles_RDD = MapPartitionsRDD[16] at values at <console>:47\n",
       "mask_tiles_withIndex = MapPartitionsRDD[18] at map at <console>:48\n",
       "mask_tile0 = FloatRawArrayTile([F@2f97cf5,7808,3892)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "FloatRawArrayTile([F@2f97cf5,7808,3892)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val mask_path = \"hdfs:///user/hadoop/usa_mask.tif\"\n",
    "    val mask_tiles_RDD = sc.hadoopGeoTiffRDD(mask_path).values\n",
    "    val mask_tiles_withIndex = mask_tiles_RDD.zipWithIndex().map{case (e,v) => (v,e)}\n",
    "    val mask_tile0 = (mask_tiles_withIndex.filter(m => m._1==0).values.collect())(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res_tile = Array(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "val res_tile = geo_tile0.localInverseMask(mask_tile0, 1, 0).toArrayDouble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new GeoTiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clone_tile = DoubleConstantNoDataArrayTile([D@71b97c2a,7808,3892)\n",
       "cloned = DoubleConstantNoDataArrayTile([D@4d6e1d19,7808,3892)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DoubleConstantNoDataArrayTile([D@4d6e1d19,7808,3892)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val clone_tile = DoubleArrayTile(res_tile, geo_num_cols_rows._1, geo_num_cols_rows._2)\n",
    "\n",
    "val cloned = geotrellis.raster.DoubleArrayTile.empty(geo_num_cols_rows._1, geo_num_cols_rows._2)\n",
    "cfor(0)(_ < geo_num_cols_rows._1, _ + 1) { col =>\n",
    "    cfor(0)(_ < geo_num_cols_rows._2, _ + 1) { row =>\n",
    "        val v = clone_tile.getDouble(col, row)\n",
    "        cloned.setDouble(col, row, v)\n",
    "    }\n",
    "}\n",
    "\n",
    "val geoTif = new SinglebandGeoTiff(cloned, geo_projected_extent.extent, geo_projected_extent.crs, Tags.empty, GeoTiffOptions.DEFAULT)\n",
    "\n",
    "//Save GeoTiff to /tmp\n",
    "val output = \"/user/emma/spring-index/BloomFinal/1980_mask.tif\"\n",
    "val tmp_output = \"/tmp/1980_mask_clone.tif\"\n",
    "GeoTiffWriter.write(geoTif, tmp_output)\n",
    "\n",
    "//Upload to HDFS\n",
    "var cmd = \"hadoop dfs -copyFromLocal -f \" + tmp_output + \" \" + output\n",
    "Process(cmd)!\n",
    "\n",
    "cmd = \"rm -fr \" + tmp_output\n",
    "Process(cmd)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
